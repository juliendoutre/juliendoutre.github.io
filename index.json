[{"content":"","date":null,"permalink":"/","section":"Julien Doutre","summary":"","title":"Julien Doutre"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"Let\u0026rsquo;s say you have a process that performs many actions involving dependency resolution and fetching, requesting various APIs, sending telemetry, etc. Something like a CI runner compiling a program for instance. How can you make sure to catch all artifacts it pulls from the outside (namely the Internet) or data it sends out?\nI tried using eBPF and Frida to achieve this but both proved to be difficult to use:\neBPF can intercept TCP packets in kernel space but TLS connections are negotiated by programs in userspace eBPF (or Frida) can attach probes to programs functions, but dependening on their language, they may use different libs to perform HTTP requests. Supporting all of them is too dauting of a task. A simpler approach would be to have HTTP requests go through a proxy server. The HTTP_PROXY and HTTPS_PROXY environment variables are a de facto standard that many tools abide by. Setting them will make sure that requests are proxied to the URL their values hold instead of being sent directly to the target.\nSetting a couple of environment variables is a good enough trade off on my side if it allows an otherwise transparent setup for the user. My end goal was to build a tool that one could wrap commands with, to monitor all their HTTP requests and get a report of what APIs were reached and what dependencies where pulled. So let\u0026rsquo;s get started!\nmkdir proxaudit cd ./proxaudit go mod init github.com/juliendoutre/proxaudit git init You can find the project source code on https://github.com/juliendoutre/proxaudit. Check out the commits history to see each iteration! First we need to create a HTTP server that will listen on a given port.\nserver := \u0026amp;http.Server{ Addr: \u0026#34;:\u0026#34; + strconv.FormatUint(*port, 10), Handler: \u0026amp;handler{logger}, ReadTimeout: 10 * time.Second, ReadHeaderTimeout: 5 * time.Second, IdleTimeout: 120 * time.Second, } Here logger is a *zap.Logger and port is an uint64 value provided by the user through a command line flag. I set up some default timeouts as a good security practice but the values are not critical to the implementation.\nhandler is a custom struct that implements the http.Handler interface defined as:\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } I wrote it as:\ntype handler struct { logger *zap.Logger } func (h *handler) ServeHTTP(rw http.ResponseWriter, req *http.Request) { h.logger.Info(\u0026#34;received request\u0026#34;, zap.String(\u0026#34;method\u0026#34;, req.Method), zap.String(\u0026#34;url\u0026#34;, req.URL.String())) httputil.NewSingleHostReverseProxy(req.URL).ServeHTTP(rw, req) } The ServeHTTP method is not doing much. It logs the request\u0026rsquo;s HTTP verb and the destination URL before deferring the proxy work to a httputil.ReverseProxy struct available in Go\u0026rsquo;s standard library.\nIf I put everything together in a main.go file:\nfunc main() { port := flag.Uint64(\u0026#34;port\u0026#34;, 8000, \u0026#34;port to listen on\u0026#34;) flag.Parse() logger, err := zap.NewProductionConfig().Build() if err != nil { log.Panic(err) } server := \u0026amp;http.Server{ Addr: \u0026#34;:\u0026#34; + strconv.FormatUint(*port, 10), Handler: \u0026amp;handler{logger}, ReadTimeout: 10 * time.Second, ReadHeaderTimeout: 5 * time.Second, IdleTimeout: 120 * time.Second, } go waitForSignal(server, logger) logger.Info(\u0026#34;Starting HTTP proxy server...\u0026#34;, zap.Uint64(\u0026#34;port\u0026#34;, *port)) if err := server.ListenAndServe(); err != nil { if errors.Is(err, http.ErrServerClosed) { logger.Warn(\u0026#34;HTTP proxy server was stopped\u0026#34;, zap.Error(err)) } else { logger.Panic(\u0026#34;Failed running HTTP proxy server\u0026#34;, zap.Error(err)) } } } and start the server with go run ./main.go it should log something like:\n{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:1733854054.4425678,\u0026#34;caller\u0026#34;:\u0026#34;proxaudit/main.go:38\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Starting HTTP proxy server...\u0026#34;,\u0026#34;port\u0026#34;:8000} and then hang, waiting for requests.\nwaitForSignal is a util function I wrote to catch signals such as SIGKILL and gracefully terminate the server:\nfunc waitForSignal(server *http.Server, logger *zap.Logger) { stop := make(chan os.Signal, 2) signal.Notify(stop, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-stop if err := server.Shutdown(context.Background()); err != nil { logger.Error(\u0026#34;Failed shutting down HTTPS proxy server\u0026#34;, zap.Error(err)) } } If I open a shell in another tab and run http_proxy=http://localhost:8000 curl http://google.com I can see the proxy logging some requests:\n{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:1733854063.6379368,\u0026#34;caller\u0026#34;:\u0026#34;proxaudit/main.go:64\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;received request\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;GET\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;http://google.com/\u0026#34;} We got a plain HTTP request proxy working!\nCode checkpoint Nowadays though, most people use HTTPS. Running http_proxy=http://localhost:8000 curl https://google.com does not result in any log on the proxy side. We could have expected this, we changed of protocol. But what happens if I run HTTPS_PROXY=http://localhost:8000 curl https://google.com?\nThe server logs an error: http: proxy error: unsupported protocol scheme \u0026quot;\u0026quot; and curl returns an error as well: curl: (56) CONNECT tunnel failed, response 502.\nWhy is this? I understood the issue while reading https://eli.thegreenplace.net/2022/go-and-proxy-servers-part-2-https-proxies/.\nA HTTPS connection can go through proxies but will only send a CONNECT request to them, indicating which host it targets. Then it\u0026rsquo;s expecting the underlying TLS connection to be tunneled as is.\nIn order to fix my code, I extended my ServeHTTP function like this:\nfunc (h *handler) ServeHTTP(rw http.ResponseWriter, req *http.Request) { h.logger.Info(\u0026#34;received request\u0026#34;, zap.String(\u0026#34;method\u0026#34;, req.Method), zap.String(\u0026#34;url\u0026#34;, req.URL.String())) if req.Method == http.MethodConnect { h.handleConnect(rw, req) } else { httputil.NewSingleHostReverseProxy(req.URL).ServeHTTP(rw, req) } } func (h *handler) handleConnect(rw http.ResponseWriter, req *http.Request) { hijacker, ok := rw.(http.Hijacker) if !ok { http.Error(rw, \u0026#34;Hijacking not supported\u0026#34;, http.StatusInternalServerError) return } clientConn, _, err := hijacker.Hijack() if err != nil { http.Error(rw, err.Error(), http.StatusServiceUnavailable) return } defer clientConn.Close() serverConn, err := net.Dial(\u0026#34;tcp\u0026#34;, req.Host) if err != nil { http.Error(rw, err.Error(), http.StatusServiceUnavailable) return } defer serverConn.Close() clientConn.Write([]byte(\u0026#34;HTTP/1.1 200 Connection Established\\r\\n\\r\\n\u0026#34;)) go io.Copy(serverConn, clientConn) io.Copy(clientConn, serverConn) } The handleConnect menthod really just returns a success status to the client and then recover the underlying TCP connection (thanks to the http.Hijacker interface casting) to simply forward all the traffic to the destination host.\nNow I can run HTTPS_PROXY=http://localhost:8000 curl https://google.com without errors!\nCode checkpoint But\u0026hellip; it\u0026rsquo;s simply logging CONNECT requests, not the underlying HTTPS requests. As the proxy blindly forward the TLS connection to the host, it does not have access to the raw content. And it\u0026rsquo;s why TLS is used for, right? Preventing eavesdroppers from intercepting cleartext traffic. Fortunately, there\u0026rsquo;s a way to overcome this though by using Man-In-The-Middle (MITM) certificate crafting.\nI read https://docs.mitmproxy.org/stable/concepts-howmitmproxyworks/#explicit-https from the mitmproxy Python project to understand the technique at play. The idea is to craft a fake certificate using a Certificate Authority (CA) under our control and that is trusted by the client to terminate the connection in the proxy. Then open a second connection to the server to forward requests after they\u0026rsquo;ve been handled by the proxy. This requires to fetch the destination\u0026rsquo;s certificate to craft a matching certificate.\nAs my end goal is to make an open source observability tool, I can ask users to trust a certificate that would intercept their traffic. I first ran:\nopenssl genrsa -out ca.key 4096 openssl req -new -x509 -days 365 -key ca.key -out ca.crt openssl req -newkey rsa:4096 -nodes -keyout server.key -subj \u0026#34;/CN=localhost\u0026#34; -out server.csr openssl x509 -req -extfile \u0026lt;(printf \u0026#34;subjectAltName=DNS:localhost\u0026#34;) -days 365 -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt to generate a CA and a certificate for my proxy before a colleague told me about https://github.com/FiloSottile/mkcert:\nbrew install mkcert mkcert -install mkcert localhost ","date":"2024-12-09","permalink":"/posts/proxaudit/","section":"Posts","summary":"","title":"Writing a HTTPS proxy in Golang"},{"content":"Last year a coworker shared with me the excellent https://gtfobins.github.io/ website, a compendium of techniques to abuse misconfigurations in Linux binaries. It\u0026rsquo;s an open source project and its code can be found on GitHub at https://github.com/GTFOBins/GTFOBins.github.io.\nI wanted to build a discovery tool leveraging this data set. I had some time on a week-end and created https://github.com/juliendoutre/gogtfobins/ to do so. It\u0026rsquo;s a Go CLI built with the cobra library exposing three commands:\ngogtfobins list to list all binaries available on the host and the functions they can eventually allow to obtain gogtfobins describe BINARY to print some details about a specific binary gogtfobins exploit BINARY FUNCTION to run an exploit for a binary Here is a more concrete example:\n# List all available binaries allowing for opening a reverse shell on the current host. gogtfobins list --function reverse-shell # Print possible exploits for the docker binary. gogtfobins describe docker # Get a reverse-shell using the docker binary. gogtfobins exploit docker reverse-shell You can install it easily with homebrew:\nbrew tap juliendoutre/gogtfobins https://github.com/juliendoutre/gogtfobins brew install gogtfobins or download a built binary from the available releases.\nThe gtfobins data is embedded thanks to a go embed directive that is then used to build both an index and a reverse index. Commands simply query this index. You can actually reuse this data structure in your own project as it is exposed in a Go module:\ngo get github.com/juliendoutre/gogtfobins Let me know if anything is missing or you found a bug by opening an issue.\nSee you next time üëã\n","date":"2024-12-03","permalink":"/posts/go-gtfobins/","section":"Posts","summary":"","title":"Living off the land in Linux!"},{"content":"I always wanted to create a video game. It\u0026rsquo;s a topic I approached a bit while working on some projects like a solution to the Synacor challenge or a R8 emulator implementation. But there were mostly coding challenges and did not involve any actual game design.\nI played a bit with Unity and even created a small platformer game with some friends for a school project (play it online here!). However I was confused by the code organization. I really wanted to manage the whole app as code and could not really achieve this. Everything had to be managed through scripts attached to objects only tracked in the IDE or weird metadata files. This was not satisfying to my nascent software engineering mindset!\nA couple of years ago, I stumbled upon the Amethyst project. I was really excited about the ECS approach and read some guides but never came to create anything concrete. And then the project stopped üò¢\nHowever some developpers seemed decided to continue the adventure and started Bevy. It\u0026rsquo;s really close to Amethyst concept-wise but they seemed to get rid of some of the cumbersome type declarations and only kept the best from this framework.\nFor those not familiar with ECS, it stands for Entity-Component-Systems. It\u0026rsquo;s a way to design games based on entities which can get attached components and updated by systems which updates their state.\nI decided to give it a try and started a new GitHub repository: https://github.com/juliendoutre/froggy.\nI took inspiration from https://github.com/bevyengine/bevy/blob/latest/examples/games/game_menu.rs to create a simple splash screen and a game menu with two buttons.\nAssets come from https://www.kenney.nl which provides an amazing collection of game assets for free ‚ù§Ô∏è\nDesigning UI components on a canvas was similar as writing HTML nodes but in Rust\u0026hellip; which felt rather cumbersome. Once I had a satisfying rendering, I decided to release my game. I skimmed through https://bevy-cheatbook.github.io/platforms.html and noticed Bevy support WASM!\nAs for the previous game I was working for, I decided to release it on GitHub pages (free hosting for the win) but this time I wanted to automate this a bit. And it happens the Rust toolchain is pretty well integrated in the GitHub actions ecosystem.\nMy first step was to add a CI workflow with several jobs to check code\u0026rsquo;s formating, run clippy, tests, build the project, and check the lock file is up to date.\nname: CI # The workflow should only run for commits in PRs and the main branch. on: push: branches: - main pull_request: branches: - \u0026#39;*\u0026#39; # Let\u0026#39;s use concurrency groups to cancel stale jobs except on the main branch. concurrency: group: ${{ github.workflow }}-${{ github.ref }} cancel-in-progress: ${{ github.ref != \u0026#39;main\u0026#39; }} # Always explicitly set a workflow permissions! permissions: contents: read One optimization I used is to cache the .target and .cargo folders so that they can be used across jobs. All my jobs therefore start with the following steps:\njobs: my-job: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses: actions/cache@v4 with: path: | ~/.cargo/bin/ ~/.cargo/registry/index/ ~/.cargo/registry/cache/ ~/.cargo/git/db/ target/ key: ${{ runner.os }}-cargo-${{ hashFiles(\u0026#39;**/Cargo.lock\u0026#39;) }} - run: rustup update stable \u0026amp;\u0026amp; rustup default stable I noticed compilation errors at build time because of missing dev libraries that I was able to fix simply with:\n- run: sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y libasound2-dev libudev-dev Then I created a CD workflow to build and deploy the game to a GitHub page:\nname: CD # The workflow should only run for commits on the main branch. on: push: branches: - main # Always explicitly set a workflow permissions! permissions: contents: read with the following jobs:\njobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses: actions/cache@v4 with: path: | ~/.cargo/bin/ ~/.cargo/registry/index/ ~/.cargo/registry/cache/ ~/.cargo/git/db/ target/ key: ${{ runner.os }}-cargo-${{ hashFiles(\u0026#39;**/Cargo.lock\u0026#39;) }} - run: rustup update stable \u0026amp;\u0026amp; rustup default stable # We need to make sure the Rust toolchain supports WASM. - run: rustup target install wasm32-unknown-unknown # Building a WASM binary. - run: cargo build --release --target wasm32-unknown-unknown # Installing some tools to optimizie the WASM binary. - run: cargo install wasm-bindgen-cli@0.2.92 wasm-opt@0.116.1 # Generating some JS code to load the WASM in a HTML canvas. - run: wasm-bindgen --no-typescript --target web --out-dir ./build/ --out-name froggy ./target/wasm32-unknown-unknown/release/froggy.wasm # Optimizing the binary for size. Experimentally, it decreased the size by 2 which saves some bandwidth for the website users (from 30M to 15M). - run: wasm-opt ./build/froggy_bg.wasm -o ./build/froggy_bg.wasm -Oz # Adding a dead simple HTML file to load the JS code and define the aforementioned canvas. - run: cp ./www/index.html ./build/index.html # Copying the assets into the build folder so that they are bundled too and served by the website. - run: cp -r ./assets ./build/assets # Uploading the build folder to artifacts. - uses: actions/configure-pages@v5 - uses: actions/upload-pages-artifact@v3 with: path: ./build deploy: # GitHub pages are now action based and not simply based on a Git branch. permissions: pages: write id-token: write environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - uses: actions/deploy-pages@v4 id: deployment It takes about 9 minutes to build and deploy the website. And here is the final result: https://juliendoutre.github.io/froggy!\nThis was a nice journey but I noticed some caveats:\nbevy does not support hot reloading writing Rust code does not let any room for quick hacks which is often needed when developing a game. In the end, most of the points mentioned in https://loglog.games/blog/leaving-rust-gamedev.\nSo next, I\u0026rsquo;d like to try Godot and give another chance to more \u0026ldquo;classic\u0026rdquo; game engines.\nSee you next time üëã\n","date":"2024-05-11","permalink":"/posts/bevy/","section":"Posts","summary":"","title":"I (almost) wrote a game in Rust with Bevy!"},{"content":" How can computers be helpful at approaching derivatives? Introduction # This article follows another one: Computers and mathematical functions. In our previous exploration of functions in the context of computers we encountered a lot of bummers. Today, let\u0026rsquo;s talk about how computers can actually be useful and solve real world problems!\nDerivative definitions #For a function \\(f\\) defined over and with its values in \\(\\mathbb{R}\\), it is said to be differentiable at a point \\(a\\) if\n$$ \\lim_{h \\rightarrow 0} \\frac{f(a + h) - f(a)}{h} $$\nexists.\nIt\u0026rsquo;s possible to define a new function for all points \\(a\\) where such a limit exists. Let\u0026rsquo;s call it \\(f\\)\u0026rsquo;s derivative, and note it \\(f\u0026rsquo;\\) or \\(\\frac{df}{dx}\\) to insist on the fact it\u0026rsquo;s differentiated for the \\(x\\) variable.\nComputing a first order derivative #With computers we can\u0026rsquo;t get the value\u0026rsquo;s limit but for small enough values of \\(h\\) we can get an approached value!\nfunc derivative(f func(x float64) float64, h, x float64) float64 { return (f(x+h) - f(x)) / h } This is pretty simple and will return results close to exact values. See for instance how it performs against the derivative of the square function for which we know an analytic expression:\nimport \u0026#34;fmt\u0026#34; func main() { fmt.Println(derivative(square, 0.00000001, 1)) // get 1.999999987845058, expected 2 fmt.Println(derivative(square, 0.00000001, 2)) // get 3.999999975690116, expected 4 } func square(x float64) float64 { return x * x } The smaller the \\(h\\), the closer the result:\nfunc main() { fmt.Println(derivative(square, 0.00000001, 2)) // get 3.999999975690116, expected 4 fmt.Println(derivative(square, 0.001, 2)) // get 4.009999999999891, expected 4 } But too small of a value will raise weird errors so we can\u0026rsquo;t push it to far:\nfunc main() { fmt.Println(derivative(square, 0.000000000000001, 2)) // get 3.5527136788005005 ?! fmt.Println(derivative(square, 0.0000000000000001, 2)) // get 0 ?!! } Derivatives all the way #Differentiating once is useful, but sometimes we need to differentiate another time, or even more. We can easily implement this through recursion:\nfunc derivativeN(n uint, f func(x float64) float64, h, x float64) float64 { if n == 0 { return f(x) } return (derivativeN(n-1, f, x+h, h) - derivativeN(n-1, f, x, h)) / h } Let\u0026rsquo;s test it is correct for the cube function:\nfunc main() { fmt.Println(derivativeN(0, cube, 0.000001, 1)) // get 1, expected 1 fmt.Println(derivativeN(1, cube, 0.000001, 1)) // get 3.0000029997978572, expected 3 fmt.Println(derivativeN(2, cube, 0.000001, 1)) // get 5.999867269679271, expected 6 } func cube(x float64) float64 { return x * x * x } It looks okay so far!\nJust one more dimension bro #Finally, let\u0026rsquo;s talk about partial derivatives. This is the generalization of the previous points to functions over \\(n\\) values:\nThe \\(f\\) partial derivative for it\u0026rsquo;s \\(i\\)-th argument is defined as:\n$$ \\frac{\\partial f}{\\partial x_i} = \\lim_{h \\rightarrow 0} \\frac{f(x_1, x_2, \u0026hellip;, x_i + h, x_n) - f(x_1, x_2, \u0026hellip;, x_i, x_n)}{h} $$\nAnd the total derivative writes as the sum of all partial derivatives:\n$$ Df = \\sum_{i=0}^n \\frac{\\partial f}{\\partial x_i} $$\nHere is a possible implementation:\nfunc derivativeN(n uint, f func(x ...float64) float64, h float64, x ...float64) float64 { if n == 0 { return f(x...) } D := 0.0 for i := 0; i \u0026lt; len(x); i++ { newValues := make([]float64, len(x)) copy(newValues, x) newValues[i] += h D += (derivativeN(n-1, f, h, newValues...) - derivativeN(n-1, f, h, x...)) / h } return D } Ok but I promised to show something actually useful. Let\u0026rsquo;s talk about physics and differential equations now üî•\nSolving differential equations 101 #WIP\n","date":"2024-04-18","permalink":"/posts/computers-and-derivatives/","section":"Posts","summary":"","title":"How can computers be helpful at approaching derivatives?"},{"content":" Walkthrough of an encoding/decoding library implementation. Introduction #It\u0026rsquo;s been a long time I\u0026rsquo;ve been fascinated by lexers, parsers and more broadly programming language theory. Since data is just a bunch of bits, how do computer split them into recognizable types? And conversely, how can they serialize in-memory types to chunks of data exchangeable over the wire?\nSince I better understand when I actually implement things, I decided to create my own parsing library and share the journey on this website. I chose to write it in Golang to avoid the burden of thinking too much about memory management, at first. Instead, I focused on API design and writing concise code (I hope).\nThis post is in part inspired by the excellent https://github.com/rust-bakery/nom library which I recomment checking out! It\u0026rsquo;s written in Rust ü¶Ä, and relies on a very modular approach to parsing which I really appreciated reading through.\nLet\u0026rsquo;s get started!\nInitialization #First of all, we need to create a new Go project:\ncd ~/dev mkdir -p godec # I\u0026#39;m bad at naming cd godec go mod init github.com/juliendoutre/godec git init code . Basic interface design #A data parsing library must provide two features:\ndecoding a blob of data to interpret it as some in-memory value (aka unmarshalling, deserializing) encoding some in-memory value into a blob of data (aka marshalling, serializing). We can start by creating a new Go file godec.go defining two very basic interfaces:\n// godec.go package godec type Encoder interface { Encode() ([]byte, error) } type Decoder interface { Decode(input []byte) ([]byte, error) } Note the Decode method also returns a slice of bytes. It\u0026rsquo;s the remainder of the input once the Decoder has been applied to it. This way we can easily chain Decoders together. This will be useful later.\nWe call a Codec any object that implements both:\n// godec.go [...] type Codec interface { Encoder Decoder } But enough abstractions for now, let\u0026rsquo;s get to some concrete applications!\nA simple use case: color codes #Let\u0026rsquo;s start with something simple:\n#3399ff \u0026lt;-- I\u0026#39;m blue, da ba dee... A color code starts with a # followed by three two-digits hexadecimal numbers, matching the red, green and blue weights of the encoded color.\nWe can see an appropriate Decoder as a state machine:\nflowchart LR; data([\"`data: []byte`\"]); red([\"`red: uint8`\"]); green([\"`green: uint8`\"]); blue([\"`blue: uint8`\"]); style data fill:#FFB7C5; style red fill:#66CDAA; style green fill:#66CDAA; style blue fill:#66CDAA; hashtag[\"#\"]; hex1[\"two-digits hex number\"]; hex2[\"two-digits hex number\"]; hex3[\"two-digits hex number\"]; termination[\"no more bytes\"]; data --\u003e hashtag; hashtag --\u003e hex1; hex1 --\u003e hex2; hex2 --\u003e hex3; hex3 --\u003e termination; hex1 -.-\u003e red; hex2 -.-\u003e green; hex3 -.-\u003e blue; And an Encoder as its \u0026ldquo;opposite\u0026rdquo;: flowchart LR; data([\"`data: []byte`\"]); red([\"`red: uint8`\"]); green([\"`green: uint8`\"]); blue([\"`blue: uint8`\"]); style data fill:#66CDAA; style red fill:#FFB7C5; style green fill:#FFB7C5; style blue fill:#FFB7C5; hashtag[\"#\"]; hex1[\"two-digits hex number\"]; hex2[\"two-digits hex number\"]; hex3[\"two-digits hex number\"]; termination[\"no more bytes\"]; hashtag --\u003e hex1; hex1 --\u003e hex2; hex2 --\u003e hex3; red -.-\u003e hex1; green -.-\u003e hex2; blue -.-\u003e hex3; hex3 --\u003e termination; termination --\u003e data; We need to build a few components already:\na box matching a given bytes slice (here simply #) a box tying an uint8 variable to a two-digits hexadecimal number a box checking there\u0026rsquo;re no bytes left a way to chain the boxes together Let\u0026rsquo;s write our first parser\u0026rsquo;s code:\n// codecs.go package godec import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; ) type ExactMatch []byte func (e ExactMatch) Encode(input []byte) ([]byte, error) { return e, nil } func (e ExactMatch) Decode(input []byte) ([]byte, error) { if bytes.Equal(e, input[:len(e)]) { return input[len(e):], nil } return nil, fmt.Errorf(\u0026#34;expected %q\u0026#34;, string(e)) } var _ Codec = ExactMatch{} I\u0026rsquo;m using type aliasing since an exact match just requires to store the bytes it needs to be checked against. The encoding logic is dead simple: it simply returns the underlying bytes slice. The decoding is a bit more involved: it compares the input slice to the underlying ExactMatch one and returns an error if it\u0026rsquo;s not a match.\nThe last line is a compile time type check to make sure ExactMatch actually implements the Codec interface. Now for the hexadecimal box:\n// codecs.go [...] type HexadecimalUInt8 struct { Variable *uint8 } func (h HexadecimalUInt8) Encode() ([]byte, error) { return []byte(fmt.Sprintf(\u0026#34;%02x\u0026#34;, uint64(*h.Variable))), nil } func (h HexadecimalUInt8) Decode(input []byte) ([]byte, error) { if len(input) \u0026lt; 2 { return nil, fmt.Errorf(\u0026#34;expected at least 2 bytes\u0026#34;) } n, err := strconv.ParseUint(string(input[:2]), 16, 8) if err != nil { return nil, err } *h.Variable = uint8(n) return input[2:], nil } var _ Codec = HexadecimalUInt8{} I can\u0026rsquo;t use type aliasing here as we need a way to store a pointer to the \u0026ldquo;tied\u0026rdquo; variable.\nEncoding and decoding are managed thanks to standard lib functions. Maybe there are more performant options but this will do for now.\nThe termination box\u0026rsquo;s code is even easier:\n// codecs.go [...] type NoMoreBytes struct{} func (n NoMoreBytes) Encode() ([]byte, error) { return nil, nil } func (n NoMoreBytes) Decode(input []byte) ([]byte, error) { if len(input) != 0 { return nil, fmt.Errorf(\u0026#34;expected no more bytes\u0026#34;) } return input, nil } var _ Codec = NoMoreBytes{} Using struct {} makes this abstraction\u0026rsquo;s size 0 which is convenient.\nWe got all our boxes but we still need a way to link them together:\n// combinators.go package godec type Sequence []Codec func (s Sequence) Encode() ([]byte, error) { var out []byte for _, codec := range s { codecOut, err := codec.Encode() if err != nil { return nil, err } out = append(out, codecOut...) } return out, nil } func (s Sequence) Decode(input []byte) (remaining []byte, err error) { remaining = input for _, codec := range s { remaining, err = codec.Decode(remaining) if err != nil { return nil, err } } return remaining, nil } A Sequence Encodes by applying its list of Codecs one after the other. Decoding works the same way.\nAll our components are ready, we can now compose them in a color Codec:\n// examples/colors/codec.go package colors import \u0026#34;github.com/juliendoutre/godec\u0026#34; func Codec(red, green, blue *uint8) godec.Sequence { return godec.Sequence([]godec.Codec{ godec.ExactMatch([]byte(\u0026#34;#\u0026#34;)), godec.HexadecimalUInt8{Variable: red}, godec.HexadecimalUInt8{Variable: green}, godec.HexadecimalUInt8{Variable: blue}, godec.NoMoreBytes{}, }) } And finally we can test it for simple cases:\n// examples/colors/codec_test.go package colors_test import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/juliendoutre/godec/examples/colors\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestColorEncoding(t *testing.T) { red := uint8(13) green := uint8(89) blue := uint8(42) codec := colors.Codec(\u0026amp;red, \u0026amp;green, \u0026amp;blue) out, err := codec.Encode() assert.NoError(t, err) assert.Equal(t, []byte(\u0026#34;#0d592a\u0026#34;), out) } func TestValidColorDecoding(t *testing.T) { var red, green, blue uint8 codec := colors.Codec(\u0026amp;red, \u0026amp;green, \u0026amp;blue) remainder, err := codec.Decode([]byte(\u0026#34;#3399ff\u0026#34;)) assert.NoError(t, err) assert.Equal(t, 0, len(remainder)) assert.Equal(t, uint8(51), red) assert.Equal(t, uint8(153), green) assert.Equal(t, uint8(255), blue) } I use the https://github.com/stretchr/testify library for testing. I added it to the project dependencies with go get -u github.com/stretchr/testify/assert. Nice, it works üéâ\nProperty based testing #Testing parsers for some values is nice but it does not provide a great coverage\u0026hellip; What about weird corner cases? Will our code handle them just fine?\nOne approach to cover more test cases is property based testing. The goal is to generate test inputs at random, feed them to our code and then check some property is observed for all outputs. In the case of a codec, one simple property we wanna respect is that decoding is the invert function of encoding.\nIt happens golang provides a property based testing framework without any dependency required! It\u0026rsquo;s based on the QuickCheck library and can be leveraged as simply as:\n// examples/colors/codec_test.go [...] func TestInversibleProperty(t *testing.T) { f := func(expectedRed, expectedGreen, expectedBlue uint8) bool { actualRed := expectedRed actualGreen := expectedGreen actualBlue := expectedBlue encoder := colors.Codec(\u0026amp;expectedRed, \u0026amp;expectedGreen, \u0026amp;expectedBlue) out, err := encoder.Encode() if err != nil { return false } decoder := colors.Codec(\u0026amp;actualRed, \u0026amp;actualGreen, \u0026amp;actualBlue) remainder, err := decoder.Decode(out) if err != nil { return false } return len(remainder) == 0 \u0026amp;\u0026amp; expectedRed == actualRed \u0026amp;\u0026amp; expectedGreen == actualGreen \u0026amp;\u0026amp; expectedBlue == actualBlue } if err := quick.Check(f, \u0026amp;quick.Config{}); err != nil { t.Error(err) } } The quick.Check(f, \u0026amp;quick.Config{}) function is where the magic happens. The library generates random inputs with types matching the f function\u0026rsquo;s signature, call it with those arguments and check it returns true or raises an error.\nA more involved use case: URLs #Wikipedia does a great job at summarizing the URL format: https://en.wikipedia.org/wiki/URL#Syntax. It even provides a syntax diagram which looks a lot like our state machine from the previous section: Picture by Alhadis on Wikipedia, under CC BY-SA 4.0 If we start writing a codec using our existing blocks we find ourselves pretty limited:\n// examples/url/codec.go package url import \u0026#34;github.com/juliendoutre/godec\u0026#34; func Codec(scheme, username, password, host *string, port *uint, path *string, query, fragment *string) godec.Sequence { return godec.Sequence([]godec.Codec{ // TODO: parse scheme godec.ExactMatch([]byte(\u0026#34;:\u0026#34;)), // TODO: parse path // TODO: parse eventual query // TODO: parse eventual fragment godec.NoMoreBytes{}, }) } We can start by implementing the scheme parser. It\u0026rsquo;s pretty specific to URL parsing, so let\u0026rsquo;s simply keep it as an unexported struct in the examples/url package:\n// examples/url/scheme.go package url import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/juliendoutre/godec\u0026#34; ) type Scheme struct { scheme *string } func (s Scheme) Encode() ([]byte, error) { for _, c := range []byte(*s.scheme) { if !(c == \u0026#39;+\u0026#39;) \u0026amp;\u0026amp; !(c == \u0026#39;.\u0026#39;) \u0026amp;\u0026amp; !(c == \u0026#39;-\u0026#39;) \u0026amp;\u0026amp; !isASCIIDigit(c) \u0026amp;\u0026amp; !isASCIILetter(c) { return nil, fmt.Errorf(\u0026#34;invalid character %q\u0026#34;, c) } } return []byte(*s.scheme), nil } func (s Scheme) Decode(input []byte) ([]byte, error) { // Reject empty schemes. if len(input) == 0 { return nil, fmt.Errorf(\u0026#34;expected a scheme\u0026#34;) } // See https://datatracker.ietf.org/doc/html/rfc1738#section-2.1: // Scheme names consist of a sequence of characters. The lower case // letters \u0026#34;a\u0026#34;--\u0026#34;z\u0026#34;, digits, and the characters plus (\u0026#34;+\u0026#34;), period // (\u0026#34;.\u0026#34;), and hyphen (\u0026#34;-\u0026#34;) are allowed. For resiliency, programs // interpreting URLs should treat upper case letters as equivalent to // lower case in scheme names (e.g., allow \u0026#34;HTTP\u0026#34; as well as \u0026#34;http\u0026#34;). i := 0 for i = 0; i \u0026lt; len(input); i++ { if !(input[i] == \u0026#39;+\u0026#39;) \u0026amp;\u0026amp; !(input[i] == \u0026#39;.\u0026#39;) \u0026amp;\u0026amp; !(input[i] == \u0026#39;-\u0026#39;) \u0026amp;\u0026amp; !isASCIIDigit(input[i]) \u0026amp;\u0026amp; !isASCIILetter(input[i]) { break } } if i == 0 { return nil, fmt.Errorf(\u0026#34;expected a scheme\u0026#34;) } *s.scheme = string(input[:i]) return input[i:], nil } var _ godec.Codec = Scheme{} Let\u0026rsquo;s write a dead simple test to validate decoding is working:\n// examples/url/codec_test.go package url_test import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/juliendoutre/godec/examples/url\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestSchemeValidDecoding(t *testing.T) { var scheme string decoder := url.Codec(\u0026amp;scheme, nil, nil, nil, nil, nil, nil, nil) remainder, err := decoder.Decode([]byte(\u0026#34;http:\u0026#34;)) assert.NoError(t, err) assert.Equal(t, 0, len(remainder)) assert.Equal(t, \u0026#34;http\u0026#34;, scheme) } Implementing the other parsers (check out the complete code at https://github.com/juliendoutre/godec/tree/main/examples/url) is pretty similar, in the end we can write more complete tests:\n// examples/url/codec_test.go package url_test import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/juliendoutre/godec/examples/url\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; ) func TestSchemeValidHTTPURLDecoding(t *testing.T) { var scheme string var username string var password string var host string var port uint var path string var query string var fragment string decoder := url.Codec(\u0026amp;scheme, \u0026amp;username, \u0026amp;password, \u0026amp;host, \u0026amp;port, \u0026amp;path, \u0026amp;query, \u0026amp;fragment) remainder, err := decoder.Decode([]byte(\u0026#34;http://google.com:443/test?page=1#title\u0026#34;)) assert.NoError(t, err) assert.Equal(t, 0, len(remainder)) assert.Equal(t, \u0026#34;http\u0026#34;, scheme) assert.Equal(t, \u0026#34;\u0026#34;, username) assert.Equal(t, \u0026#34;\u0026#34;, password) assert.Equal(t, \u0026#34;google.com\u0026#34;, host) assert.Equal(t, uint(443), port) assert.Equal(t, \u0026#34;/test\u0026#34;, path) assert.Equal(t, \u0026#34;page=1\u0026#34;, query) assert.Equal(t, \u0026#34;title\u0026#34;, fragment) } func TestSchemeValidPostgresDecoding(t *testing.T) { var scheme string var username string var password string var host string var port uint var path string var query string var fragment string decoder := url.Codec(\u0026amp;scheme, \u0026amp;username, \u0026amp;password, \u0026amp;host, \u0026amp;port, \u0026amp;path, \u0026amp;query, \u0026amp;fragment) remainder, err := decoder.Decode([]byte(\u0026#34;postgres://user:password@localhost:5432/database\u0026#34;)) assert.NoError(t, err) assert.Equal(t, 0, len(remainder)) assert.Equal(t, \u0026#34;postgres\u0026#34;, scheme) assert.Equal(t, \u0026#34;user\u0026#34;, username) assert.Equal(t, \u0026#34;password\u0026#34;, password) assert.Equal(t, \u0026#34;localhost\u0026#34;, host) assert.Equal(t, uint(5432), port) assert.Equal(t, \u0026#34;/database\u0026#34;, path) assert.Equal(t, \u0026#34;\u0026#34;, query) assert.Equal(t, \u0026#34;\u0026#34;, fragment) } I\u0026rsquo;m not going to expand too much on this but there\u0026rsquo;s probably room for improvements and it could definitely use some more testing!\nConclusion #And here we go, we wrote a simple Go parser library with very basic primitives and are able to use it to parse two data formats: hexadecimal color codes and URLs.\nI intentionally did not build a lot of basic blocks. When you have a look at https://github.com/rust-bakery/nom it provides many utils but in Go, abstraction (understand interfaces) has a cost.\nOne next step could be supporting more complex formats such as JSON but this will be for another day!\nSee you next time üëã\n","date":"2024-04-03","permalink":"/posts/lets-write-a-parsing-library-in-go/","section":"Posts","summary":"","title":"Let's write a parsing library in Go!"},{"content":" Exploring the relationship between computers functions and calculus Introduction # This article follows another one: How do computers understand and store numbers?. If data encoding is instrumental to information processing, it\u0026rsquo;s only half of the story. You can\u0026rsquo;t call it processing if it\u0026rsquo;s not performing some kind of computations!\nApplications and functions #In mathematics, this is a role played by applications. Given a source set \\(A\\) and a destination set \\(B\\), an application \\(a\\) is simply a mapping from all elements of \\(A\\) to elements of \\(B\\). It writes as: $$ a: A \\longrightarrow B $$ A and B can be cartesian products of other sets. This is a pedantic way of saying an application can map multiple inputs to multiple outputs:\n$$ a: A \\times B \\times C \\longrightarrow D \\times E $$\nApplications are commonly called functions when they produce numbers. Here is the square function for instance: $$ f: \\begin{cases} \\mathbb{R} \\longrightarrow \\mathbb{R} \\cr x \\longmapsto x^2 \\end{cases} $$\nIn computer science, there\u0026rsquo;s really no distinction, all common programming languages call their units of processing a \u0026ldquo;function\u0026rdquo;.\n// The square function for floating numbers encoded on 64 bits. func f(x: float64) float64 { return x * x } // A function returning the opposite of a vector in cartesian coordinates encoded on 64 bits. func g(a: float64, b: float64) -\u0026gt; (float64, float64) { return -a, -b } Inputs are called parameters and the concrete values used inside the function\u0026rsquo;s body are called arguments.\nAll functions are the same, kind of #Talking about computers, we just saw in our previous article that they really just understand sequences of bits of various lengths. They can be interpreted differently, but in the end they are just lists of 0 and 1.\nTherefore, on a computer, all functions can be defined as: $$ f: \\lbrace 0,1\\rbrace^N \\longrightarrow \\lbrace0,1\\rbrace^M $$\nwhere \\(N\\) and \\(M\\) are numbers of bits for the input and output.\nThose inputs and outputs can be splitted in various types which are often indicated explicitely by programmers\nfunc f(a: float64, b: int32, c: uint8) (float64, int32) { [...] } Some languages like Python are smart enough to figure out the types of the arguments they are called with. However this comes with some caveats. Explicit typing allow the compiler to catch errors earlier, to optimize the code more aggressively, and is a good documentation practice. In this serie of articles, I chose to illustrate coding examples with Golang, which is an explicitely typed language. Note that since its version 3.5, Python also support type hints even if they are not actually checked by the interpreter. A story of space and time #At this point, you may think about something: if functions are just mapping of a bits sequence to an other, would it not be easier to simply pre-compute all results and store them in a big key-value store? This way we just have to search in our store for the value associated with a certain key, ie. a specific bits sequence.\nWell, this is an actual optimization mechanism! For expensive computations which may take seconds to run a function for a single set of inputs, it makes sense to cache some results. This technique is also known as memoization.\nHowever the cardinality of the input set may cause this cache\u0026rsquo;s size to exceed the available memory (never forget we\u0026rsquo;re tied to actual physical resources). And maybe they\u0026rsquo;re some inputs that will never be used. As everything in life, this is a tradeoff, a question of balance between the time one is ready to spare at runtime, and the storage resources at disposal.\nI like to remind myself this saying attributed to Donald Knuth: \u0026ldquo;Premature optimization is the root of all evil\u0026rdquo;. Most of the time, caching intermediate results won\u0026rsquo;t be efficient (it may even actually harm performances) and will create additional complexity in the code so it\u0026rsquo;s not worth it. Exotic functions #In mathematics courses and especially exercices, functions often behave nicely. If it\u0026rsquo;s not clear what I mean by that, let\u0026rsquo;s have a look at three examples of computers weirdness.\nRecursion #This case exists in mathematics but it\u0026rsquo;s often encounted in computer science as it is the base of many algorithms. For instance, let\u0026rsquo;s consider the Fibonacci sequence: $$ f: \\begin{cases} \\mathbb{N} \\longrightarrow \\mathbb{N} \\cr 0 \\longmapsto 1 \\cr 1 \\longmapsto 1 \\cr n \\longmapsto f(n-1) + f(n-2), \u0026amp;\\forall \u0026amp; n \u0026gt; 1 \\end{cases} $$\nHere is some code implementing it:\nfunc f(n: uint) -\u0026gt; uint { if n == 0 || n == 1 { return 1 } return f(n - 1) + f(n - 2) } It\u0026rsquo;s easy to handle cases in code with if-else statements. This is mandatory for those functions to reach termination. Else they are at risk of neved ending in an infinite recursion.\nAnd you guessed it, we live in a finite world! There\u0026rsquo;s a limit on the number of recursions that can happen in a program execution. Every time you call a function, some context is stored in memory, in a place called the stack. And this stack can\u0026rsquo;t grow passed a certain limit. When this limit is hit, it produces a stack overflow error.\nDiscontinuous functions #Most functions seen at school are continuous. Intuitively, it means that for a small input variation, the output won\u0026rsquo;t variate a lot either. There\u0026rsquo;s a more rigorous definition: a function \\(f: \\mathbb{R} \\longrightarrow \\mathbb{R}\\) is said to be continuous in \\(a \\in \\mathbb{R}\\) if: $$ \\forall x \\in \\mathbb{R}, \\forall \\epsilon \u0026gt; 0 , \\exists \\alpha \u0026gt; 0, |x - a| \u0026lt; \\alpha \\implies |f(x) - f(a)| \u0026lt; \\epsilon $$\nTechnically, since there\u0026rsquo;s a limit on the resolution floating numbers can have, no such function exists for computers. However, this issue put aside, it\u0026rsquo;s also really easy to craft weird functions with code. For instance, check out:\nfunc f(x: float64) float64 { if x \u0026lt; 0 { return 0 } return 1 } It is a step function, continous everywhere except at \\(0\\).\nSide effects #Finally, let\u0026rsquo;s talk about yet another issue tied to the physical world. Computer functions can have hidden behaviour. This is scary, right?\nThe truth is computers are rarely alone in today\u0026rsquo;s world. There are connected to Internet, they have access to storage disks, databases, clocks, etc. Those devices are accessible through dedicated functions which can be called as any other one. Let\u0026rsquo;s take an example:\nfunc f(x: float64) float64 { cachedValue := getValueOverTheNetwork(x) if cachedValue != nil { return cachedValue } valueToCache := x * x setValueOverTheNetwork(valueToCache) return valueToCache } This function computes the square of a number but involves a caching mechanism depending on a network connection.\nAnd this raises a lot of questions. It could fail when the network becomes unavailable. Or someone could change the cache\u0026rsquo;s state independently from this code.\nPlenty of scenarios open up because of this new hidden dependency that does not change the actual logic. Functions which don\u0026rsquo;t embed any external dependencies like this are call pure functions.\nLet\u0026rsquo;s have a look at another impure function:\nfunc f(x: float64) bool { cachedValue := getValueOverTheNetwork(x) if cachedValue != nil { return true } setValueOverTheNetwork(valueToCache) return false } This one simply tells if a number is available in the cache, and insert it if it\u0026rsquo;s not the case. The first time it runs, it will return false but the second time, it will return true. Repeated executions of the function for the same input don\u0026rsquo;t give the same results!\nFunctions which do return the same results all the time are called idempotent.\nConclusion #We reached the end of our second exploration of the gap between mathematics and computer science. This one was fairly theorical but it covers some bizarreries you\u0026rsquo;re faced with all the time when writing code.\nIn the next article, we\u0026rsquo;ll talk about more concrete applications of computers, specifically how they can help solving differential equations.\nSee you next time üëã\n","date":"2024-03-28","permalink":"/posts/computers-and-functions/","section":"Posts","summary":"","title":"Computers and mathematical functions"},{"content":" How do computers understand and store numbers? Introduction #If you followed mathematics courses you\u0026rsquo;re probably aware there are several types of numbers. Natural numbers (also known as positive integers), relative integers with which comes the notion of negative numbers, rationals which are a ratio of two relative numbers (ü§Ø), irrationals which can\u0026rsquo;t be expressed as a fraction (like \\(\\pi\\)), reals which are the union of rationals and irrationals, and finally complex numbers which can be seen as a pair of two reals.\nHowever when starting coding, one may find those abstractions lacking and instead encounter weird types such as in Golang: uint8, int32 or float64. In this first article about computers and mathematics, let\u0026rsquo;s try to understand what they mean and how they relate to \u0026ldquo;actual\u0026rdquo; numbers.\nBase 2 #First we need to realize that computers are just a bunch of switches connected together in a smart way.\nA switch can be in one of two states: open or closed, which computer scientists chose to name 0 and 1. Some people also call them false and true, which makes more sense when working with propositions rather than numbers.\nA major contributor to propositional logic based on these premises was George Boole, hence it is often referenced as boolean algebra. One can combine multiple switches to store a sequence (or vector) of bits, that is to say, an ordered list of 0 and 1. For instance 01010111 is a sequence of 8 bits. For historical reasons, a sequence of such a length is called a \u0026ldquo;byte\u0026rdquo;.\nAnd then comes a very interesting result thanks to euclidian division: any natural number can be expressed as such a sequence. Think about it, let\u0026rsquo;s take a number like \\(13\\). If we divide it by \\(2\\), we obtain \\(13 = 2 * 6 + 1\\). If we decompose \\(6\\) itself, we obtain \\(13 = 2 * (2 * 3) + 1\\) and by decomposing \\(3\\) itself we get \\(13 = 2 * (2 * (2 * 1 + 1)) + 1\\). Once developped and grouped by power of two we obtain \\(13 = 2^3 + 2^2 + 1\\).\nStart seeing a pattern here? Let\u0026rsquo;s write the same expression again but showing all powers of two:\n\\(13 = 1 * 2^3 + 1 * 2^2 + 0 * 2^1 + 1 * 2^0\\)\nIn mathematics, any number power 0 gives 1, so \\(2^0 = 1\\). What if we only took the ones and zeros from the previous expression and put them in a list? We\u0026rsquo;d get 1101. Et voil√†, we wrote our initial number, \\(13\\), in a different writing base, in this case, in base 2 üéâ!\nNote that you can use many different bases to write a number but since computers can only understand open or close switches we are only interested in base 2!\nIn this case we wrote the successive powers from the left to the right in descending order. This is called the most significant bit (MSB) notation but you can write in the other direction and get 1011 which is named least significant bit (LSB) notation. The operation of taking a decimal written number and transform it in a base 2 number can be reversed. If we take our previous byte 01010111, we can compute it as:\n\\(0 * 2^7 + 1 * 2^6 + 0 * 2^5 + 1 * 2^4 + 0 * 2^3 + 1 * 2^2 + 1 * 2^1 + 1 * 2^0 = 87\\)\nCan you tell from a base 2 written number if it\u0026rsquo;s odd or even in less than a second? For sure! Check its last bit. If it\u0026rsquo;s zero, it is even, if it\u0026rsquo;s one, it is odd. Natural integers #Thanks to this ground work definition we can now work with any natural number! Right?\nRight?\nWell the thing is computers have limited resources. You can\u0026rsquo;t write numbers bigger than the maximum number of switches you have available. Most electronic chips are designed to handle numbers with the following sizes:\n8 bits (aka a \u0026ldquo;byte\u0026rdquo;): this is the smallest size available on most computers. 16 bits 32 bits 64 bits: this is the biggest size available. Those are often available under types such as unsigned integer \u0026lt;N\u0026gt; or uint\u0026lt;N\u0026gt; with N being one of 8, 16, 32 or 64.\nYou can always write a number with more switches than it takes to store it: just add zeros to its left until you reach the right size. For instance 13 is represented as 00001101 on a single byte.\nHowever you can\u0026rsquo;t write a number with less switches than it\u0026rsquo;s base 2 size and expect things to work well! This may sound like an edge case but think about operations like multiplications. If we wanna stay on a byte only and multiply 10000000 and 10111010 together, the result won\u0026rsquo;t fit! This is what is called an integer overflow.\nHowever with 64 bits, you can store numbers as big as \\(18‚ÄØ446‚ÄØ744‚ÄØ073‚ÄØ709‚ÄØ551‚ÄØ615\\) which should be able to cover most of your use cases üòÅ\nRelative integers #What about negative integers?\nOne simple way of supporting them would be to add one extra bit to natural integers to indicate their sign. In this case, \\(13\\) would be spelled 000001101, and \\(-13\\) 100001101.\nThat works but this is not super convenient, our microships can\u0026rsquo;t really handle 9-bits numbers\u0026hellip; ü§î\nOk, let\u0026rsquo;s keep 8-bits numbers (or multiples of 8-bits) but use their first bit as a signing bit. We won\u0026rsquo;t be able to store relative numbers as big as natural ones (this covers \\(\\rrbracket-128;128\\llbracket\\) instead of \\(\\rrbracket-256;256\\llbracket\\)) but it\u0026rsquo;ll be easier for everyone. In this case \\(-13\\) writes as 10001101.\nIt\u0026rsquo;s better but what about 0? With this schema, both 10000000 and 00000000 would be acceptable notations. This is a bit awkward\u0026hellip;\nHopefully, there\u0026rsquo;s a solution named the two\u0026rsquo;s complement method.\nWIP\nRelative integers are often available under types such as integer \u0026lt;N\u0026gt; or int\u0026lt;N\u0026gt; with N being one of 8, 16, 32 or 64.\nRational numbers #We could write rational numbers as a couple of two relative numbers, the numerator and the denominator. However this writing would be unique only if those two numbers are coprime. This would put a lot of responsabilities on the developer to put the right numbers ahead of time. Instead we\u0026rsquo;ll just try to use the same method to describe all real numbers.\nReal numbers #As we already emphasized, computers have finite resources. And therefore, they can\u0026rsquo;t describe or manipulate numbers with an infinite sequence of digits. So basically, computers can\u0026rsquo;t reason about \\(\\frac{1}{3}\\) or \\(\\pi\\).\nHowever they can reason about an approximated value with a certain error margin. Here comes a notion well known by physicists: scientific notation.\n$$ \\pi \\approx 3.14159265*10^0 $$\n$$ \\frac{1}{3} \\approx 3.33*10^{-1} $$\nThe trick is basically to separate a number in two parts:\na mantissa which stores the significant digits for the number. an exponent which stores the power of \\(10 \\) to apply to the mantissa to \u0026ldquo;shift\u0026rdquo; the comma to the right position. This is why they are called floating numbers, the comma is \u0026ldquo;floating\u0026rdquo; in the mantissa according to the exponent\u0026rsquo;s value.\nBoth the mantissa and the and exponent can be stored as signed integers, but that does not mean the same thing:\nif the mantissa is negative, the number is negative if the exponent is negative, the number belongs to \\(]-1;1[\\) People agreed on the IEEE 754 standard to define the length of the mantissa and exponents. Two formats emerged, to accomodate different bit sizes:\n32 bits floating numbers: 23 bits mantissa + 1 bit to indicate the number\u0026rsquo;s sign + 8 bits exponent 64 bits floating numbers: 52 bits mantissa + 1 bit to indicate the number\u0026rsquo;s sign + 11 bits exponent And yes the sign is actually stored in a dedicated bit so we can define \\(0\\) in two different ways which is weird. The format also supports special values to indicate \\(\\infty\\) and \\(-\\infty\\) or an indeterminate form (often called NaN for \u0026ldquo;Not a Number\u0026rdquo; in computer science).\nAnyway, with those two new types at hand (float32 and float64 in Golang for instance) one can describe numbers in \\(]-3.4 * 10^{38} ; -1.2 * 10^{-38}[ \\cup \\{ 0 \\} \\cup ]1.2 * 10^{-38} ; 3.4 * 10^{38}[\\) and \\(]-1.8 * 10^{308} ; -2.2 * 10^{-308}[ \\cup \\{ 0 \\} \\cup ]2.2 * 10^{-308} ; 1.8 * 10^{308}[\\) respectively.\nComplex numbers #We\u0026rsquo;re close to the end of our journey! There\u0026rsquo;s one last category of numbers. They\u0026rsquo;re not pretty common but are powerful enough to deserve a mention here: complex numbers. They are not called this way because they are difficult to understand but rather because they work like a complex composed of two units, a real part and an imaginary one. And therefore, a complex number can simply be seen as a pair of two reals.\nUsually, programming language don\u0026rsquo;t support complex numbers by default so you have to import external libraries or define them yourselves as a new composite type:\ntype complex64 struct { real float32 imaginary float32 } Then it\u0026rsquo;s up to you to define operations on them!\nSome languages like Golang actually do provides native complex64 (two float32s) and complex128 (two float64s) types. Conclusion #Wow, that was a lot! Let\u0026rsquo;s do a quick recap:\ncomputers can only \u0026ldquo;understand\u0026rdquo; natural numbers written in base 2 because they are just a bunch of switches. mathematics are not limited by the physical world: imagination (and therefore coffee ‚òï) is the only limit! When dealing with computers, you always need to take into account the hardware you\u0026rsquo;re working with. relative numbers require a small trick to be efficiently understood by computers: the two\u0026rsquo;s complement method. real numbers are lies, they can only be stored as approximated values. with all these primitives established, one can build more abstractions such as complex numbers, vectors, whatever you want really! In the next post, we\u0026rsquo;ll talk about another interesting mathematical beast: functions!\nSee you next time üëã\n","date":"2024-03-25","permalink":"/posts/computers-and-numbers/","section":"Posts","summary":"","title":"How do computers understand and store numbers?"},{"content":"I wanted to have my own blog for a long time. Finally, some day last week, I found the time to set up one. This article will reflect on my thought process and the stack I ended up choosing.\nMy requirements were pretty straigthforward. I wanted:\nto write posts using just markdown. I\u0026rsquo;m not a fan of fancy text editors, they\u0026rsquo;re not reactive enough. Being able to write in my IDE (vscode) where I already manage my code and my terminal makes it easier for me to gather all my tools at the same place. to host the website myself, not just posting on Medium or Wordpress for instance. I wanted to be able to control the very content I would expose publically from the articles\u0026rsquo; body to the pages\u0026rsquo; HTML. the solution to be as cheap as possible. Do I really need to elaborate? Additionally, I did not want to build something from scratch, especially not relying on JS frameworks like React which are way too overkill for small projects. Moreover I\u0026rsquo;m not a frontend engineer, I\u0026rsquo;m really bad at drawing with CSS (I still struggle centering \u0026lt;div\u0026gt; inside flex boxes, how do these guys have their tags behave as they want them to?! ü§Ø).\nNaturally, the go-to for static websites supporting markdown is Hugo. It did not take me a lot of time to realize it was a perfect fit for my use case:\nbrew install hugo hugo new site juliendoutre.github.io and I had my project initialized.\nhugo serve and I had a locally version of the website running.\nWhat took me the most time to figure out was obviously (and as foresaw my friend Edouard) which theme to use.\nI had vague memories of the Gitbook project which I liked the chapter-based organization with a nice vertical left side panel. I checked their website and noticed they stopped supporting their self-hosted solution to focus on a SAAS platform. Too bad ü§∑ Plus it did not really fit a blog post use case, missing a lot of features I could find elsewhere.\nAfter exploring the Hugo theme showcase I ended up choosing the Congo theme which was appealing to me for the following reasons:\nit has a search bar it has a dark mode the home page can show as a profile page configuration options are crystal clear it uses Tailwind and I heard it\u0026rsquo;s the cool new thing. The only non-trivial customization was changing the default flaticon. I had to lookup some other persons\u0026rsquo; blogs source code to find the right file names to use in the static folder of my project.\nRegarding the hosting, I considered for a second deploying everything in my AWS account using S3 and CloudFront. But in the end, GitHub pages is easier to use, integrates seamlessly with GitHub actions, plus it\u0026rsquo;s free (I don\u0026rsquo;t even have to pay for a domain name)!\nMy current development workflow is pushing to the main branch, waiting for the GitHub action to generate the public folder to the gh-pages branch, which is then served by GitHub pages on the domain matching the repository\u0026rsquo;s name. I\u0026rsquo;ll see how this can be improved in the future!\nIn the meantime, if you\u0026rsquo;re curious, you can check this website source code at https://github.com/juliendoutre/juliendoutre.github.io ü§ì\nSee you next time üëã\n","date":"2023-04-03","permalink":"/posts/how-i-built-this-website/","section":"Posts","summary":"","title":"How I built this website"},{"content":"This is the first post on this website!\n","date":"2023-03-31","permalink":"/posts/hello-world/","section":"Posts","summary":"","title":"Hello World!"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"Books I enjoyed reading and recommend checking out!\n","date":"0001-01-01","permalink":"/readings/","section":"Julien Doutre","summary":"","title":"Readings"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"}]